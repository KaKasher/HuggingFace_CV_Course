{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 0. Some transformers background\n",
    "https://huggingface.co/learn/nlp-course/chapter1/3?fw=pt"
   ],
   "id": "adeaa63c7452ba95"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "`pipeline()` - The most basic object in the hf Transformers library. They are an easy way to use models for inference.\n",
    "https://huggingface.co/docs/transformers/main_classes/pipelines"
   ],
   "id": "cc9cb19d9f89abfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T14:21:50.498301Z",
     "start_time": "2024-05-01T14:21:49.109188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"zero-shot-classification\")\n",
    "classifier(\n",
    "    \"Today we're going to be playing mario kart, I hope I can earn so many coins\",\n",
    "    candidate_labels=[\"education\", \"gaming\", \"business\"],\n",
    ")"
   ],
   "id": "4cd9c9810d5ded93",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': \"Today we're going to be playing mario kart, I hope I can earn so many coins\",\n",
       " 'labels': ['gaming', 'business', 'education'],\n",
       " 'scores': [0.9950950145721436, 0.0030712091829627752, 0.0018337785732001066]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### General transformer model architecture",
   "id": "9ba2178fb54ccbaf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Model is primarily composed of two parts:\n",
    "1. Encoder - recieves an input and builds a representation of it. It means that the model is optimized to acquire understanding of the input data.\n",
    "2. Decoder - takes the representation and generates an output. It means that the model is optimized to generate the output data.\n",
    "\n",
    "Attention layers - The key to the transformer architecture is the attention mechanism. It allows the model to focus on different parts of the input data when generating the output data."
   ],
   "id": "e38dbb3ea96c821"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "9e824fec46aab2b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
